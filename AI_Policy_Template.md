# AI Use Policy (Template)

**Company:** [Company Name]  
**Industry:** [Industry]  
**Date:** [Date]

---

## 1. Purpose and Applicability
This AI Use Policy outlines principles and guardrails for responsible use of Artificial Intelligence tools at the Company, particularly Generative AI.
The purpose of this policy is to ensure ethical, transparent, and compliant use of AI technologies while mitigating associated risks.
This policy applies to all employees, contractors, and third-party users with access to Company AI tools and systems.

## 2. Scope
This policy covers all AI tools used within the Company, including but not limited to GenAI, machine learning, and predictive analytics.
It encompasses the collection, processing, and utilization of data through AI systems.

## 3. Approved AI Tools
- Employees may use AI tools that have been approved by the IT department and meet Company security standards.
- Examples of allowed AI tools: customer support chatbots, data analysis algorithms, and predictive analytics tools.
- Use of approved tools requires that they are only accessed through a company-provided account (personal accounts prohibited).

## 4. Prohibited AI Tools
- Use of any AI tools that infringe upon privacy laws or violate ethical guidelines is strictly prohibited.
- Examples of prohibited AI tools: facial recognition systems without explicit consent, biased AI models, or unauthorized data scraping tools.

## 5. Guidelines and Guardrails

### 5a. Guidelines
1. AI-generated content should be reviewed by a human to ensure it's appropriate for its intended purpose.
2. Understand that GenAI tools may be useful but are not a substitute for human judgment and creativity.
3. Understand that many GenAI tools are prone to "hallucinations," false answers or information, or information that is subtly wrong.
4. Treat every bit of information you provide to a GenAI tool as if it will go viral on the Internet, attributed to you or the Company, regardless of the settings you have selected within the tool (or the assurances made by its creators).
5. Inform your supervisor when you have used a GenAI tool to help perform a task.
6. Verify that any response from a GenAI tool that you intend to rely on or use is accurate, appropriate, not biased, not a violation of any other individual or entity's intellectual property or privacy, and consistent with Company policies and applicable laws.

### 5b. Data Guardrails

**1. Only input the data you need**
Only input data that is required for the purpose for which you are using the AI tool, and ensure the data you are using has been approved by your legal business partner for your use case.

**2. Do not input Sensitive Personal Data**
This includes information such as social security numbers, financial information like credit card or bank account numbers, personal addresses, or personal health information.

**3. Do not input any Restricted Data**
This may include things like material nonpublic information, SOX-controlled data, Company trade secrets, or internal security controls.

**4. Do not input access credentials**
Do not input system access credentials (for our systems or those of any third party).

**5. Additional restrictions**
[None specified]

**6. Do not use GenAI tools to make or help you make employment decisions**
Do not use GenAI tools to make or help you make employment decisions about applicants or employees, including recruitment, hiring, retention, promotions, transfers, performance monitoring, discipline, demotion, or terminations.

**7. Do not upload or input any confidential, proprietary, or sensitive Company information**
Do not upload or input any confidential, proprietary, or sensitive Company information into any GenAI tool. Examples include passwords and other credentials, protected health information, personnel material, information from documents marked Confidential, Sensitive, or Proprietary, or any other nonpublic Company information that might be of use to competitors or harmful to the Company if disclosed. This may breach your or the Company's obligations to keep certain information confidential and secure, risks widespread disclosure, and may cause the Company's rights to that information to be challenged.

**8. Do not represent work generated by a GenAI tool as being your own original work**
[Prohibited]

**9. Do not integrate any GenAI tool with internal Company software**
Do not integrate any GenAI tool with internal Company software without first receiving specific written permission from your supervisor and the IT Department.

**10. Do not use GenAI tools other than those on the approved list**
Do not use GenAI tools other than those on the approved list from the IT Department. Malicious chatbots can be designed to steal or convince you to divulge information.

#### PDPA Compliance (Singapore)
* **PDPA Compliance - Personal Data Collection**: Ensure that any personal data collected through AI tools complies with the Personal Data Protection Act 2012 (PDPA). Organizations must notify individuals about the purposes of collection, use, or disclosure of their personal data.
* **PDPA Compliance - Consent Requirement**: Obtain consent from individuals before collecting, using, or disclosing their personal data, unless an exception under the PDPA applies.
* **PDPA Compliance - Data Accuracy**: Make reasonable efforts to ensure that personal data collected is accurate and complete, especially if it will be used to make decisions affecting individuals or disclosed to other organizations.

## 6. AI-Generated Output Guardrails

### AI Only Responses
If an AI feature will directly present a response to customers or third parties without human review or intervention, you must disclose to the customer that they are:
- Engaging solely with an AI.
- Responsible for checking it for accuracy.
- Responsible for checking the response for detectable bias.

*Example Disclosure: "This response has been generated by an AI tool and has not been reviewed by a human being, you are responsible for checking for accuracy and bias."*

### Generating Images/Voice/Video
If you're using AI to generate content, please follow these guidelines:
- Check output for any indication of third-party ownership, such as trademarks or watermarks, and don't use any output that contains such content.
- If you are using an AI tool to replicate someone's image, likeness, or voice - you need to get their express written permission first. Please reach out to legal counsel to coordinate permission.

### Generating Code
If an AI feature will generate code, this requires additional review.

## 7. Transparency, explainability, and accountability
- Employees must be transparent about the use of AI in their work, ensuring that stakeholders are aware of the technology's involvement in decision-making processes.
- Employees must utilize Company's centralized system for AI governance and compliance efforts to ensure transparency of proposed and active AI activities.
- Employees are responsible for the outcomes generated by AI systems and should be prepared to explain and justify those outcomes.
- Employees should report any concerns or potential violations of this AI policy to the designated authority within the Company. [Link to an external reporting resouce or insert a designated reporting email.]
- The Company will investigate and address reported issues promptly.
- AI systems and models should provide clear explanations of their decision-making processes, especially when impacting individuals.
- Ensure that AI tools are understandable to non-technical stakeholders and that their implications are communicated transparently.

#### Singapore Model AI Governance Framework (Agentic AI)
The Company aligns with the Singapore Model AI Governance Framework, specifically the supplementary guidance for Agentic AI systems (January 2026), which addresses unique risks from autonomous agents including:
- Agentic Loop Risks: Monitoring and controlling AI systems that can iteratively refine their own actions
- Tool Use Accountability: Clear tracking of which AI agent invoked which external tool or API
- Explainability for Multi-Step Decisions: Providing audit trails for complex, multi-turn agent reasoning

## 8. Implementation and Monitoring

### 8a. AI Governance Board
A multidisciplinary AI risk management team ('AI Governance Board') comprised of a diverse team of experts, including data scientists, legal and compliance professionals, and ethics specialists, will ensure that AI initiatives are developed and deployed responsibly, in compliance with relevant laws and regulations, and with ethical considerations in mind. The AI Governance Board will create and define roles and responsibilities for designated committees critical to the oversight of the Company's AI initiatives.

### 8b. Designated AI Officer
A designated AI Officer will be responsible for overseeing the implementation of this policy, providing guidance and support to employees, and ensuring compliance with relevant laws and regulations.

### 8c. Periodic Reviews
The AI Officer will conduct periodic reviews of AI system use within the company to ensure adherence to this policy, identify any emerging risks, and recommend updates to the policy as necessary.

## 9. Compliance and legal
- Legal and Security will monitor and investigate suspected and/or reported violations of this policy. Depending on the results of any investigations, violations may be escalated to Leadership to determine the appropriate action.
- All AI tools and processes must comply with applicable laws, regulations, and industry standards.
- Periodic audits of AI systems may be conducted to ensure ongoing compliance.

## 10. Consequences of policy violation
Violating this policy may result in disciplinary action, up to and including immediate termination, and could result in legal action. If you are concerned that someone has violated this policy, report this behavior to your supervisor or any member of Human Resources.

## 11. Appendix - Related Documents and References
This AI Usage Policy should be read in conjunction with the following related documents and frameworks:

### Internal Governance Documents
- AI Governance Framework and Policy
- Data Protection and Privacy Policy
- Information Security Policy
- Enterprise Risk Management Framework
- Employee Code of Conduct
- Acceptable Use Policy for IT Systems

### Regulatory Frameworks and Standards
- Singapore Personal Data Protection Act 2012 (PDPA)
- Singapore Model AI Governance Framework (IMDA, 2026)
- Supplementary Guidance for Agentic AI Systems (January 2026)
- ISO/IEC 42001:2023 - AI Management System
- NIST AI Risk Management Framework

### Approved AI Tools List
- List of Company-Approved Generative AI Tools (maintained by IT Department)
- AI Tool Risk Assessment Matrix
- Third-Party AI Vendor Agreements

### Training and Resources
- AI Ethics and Responsible Use Training Materials
- Prompt Engineering Best Practices Guide
- AI Incident Response Procedures
- FAQ: Common Questions About AI Use at the Company

---
*Note: All referenced documents are available on the company intranet or through the Legal/Compliance department. Employees are responsible for staying updated on changes to related policies and frameworks.*
